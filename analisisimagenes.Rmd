---
title: "AnalisisImagenes"
output: html_document
date: "2025-12-15"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(jpeg)
library(class)
library(caret)
library(randomForest)

# Definir la ruta base
ruta_base_imagenes <- "imagenes"

# lectura de las imagenes de noche
ruta_noche <- file.path(ruta_base_imagenes, "nighttime")
archivos_noche <- list.files(
  path = ruta_noche,
  pattern = "\\.jpe?g$",
  full.names = TRUE,
  recursive = FALSE
)

df_noche <- data.frame(
  ruta = archivos_noche,
  etiqueta = 0 # Noche
)


# Leer y etiquetar imágenes del subdirectorio dia

ruta_dia <- file.path(ruta_base_imagenes, "daytime")
archivos_dia <- list.files(
  path = ruta_dia,
  pattern = "\\.jpe?g$",
  full.names = TRUE,
  recursive = FALSE
)

df_dia <- data.frame(
  ruta = archivos_dia,
  etiqueta = 1 # Día
)

# lectura de las imagenes de día

datos_imagenes <- rbind(df_noche, df_dia)


set.seed(42) 

indices_entrenamiento <- createDataPartition(
  y = datos_imagenes$etiqueta,
  p = 0.8,
  list = FALSE 
)

# Crear los conjuntos de datos de TRAIN y TEST
datos_train <- datos_imagenes[indices_entrenamiento, ]
datos_test <- datos_imagenes[-indices_entrenamiento, ]


```

```{r}
extraer_rgb <- function(df_datos) {
  
  # Matriz para R, G, B
  features <- matrix(0, nrow = nrow(df_datos), ncol = 3)
  colnames(features) <- c("R_mediana", "G_mediana", "B_mediana")
  
  cat("Extrayendo RGB de", nrow(df_datos), "imágenes...\n")
  
  for (j in 1:nrow(df_datos)) {
    tryCatch({
      img <- readJPEG(df_datos$ruta[j])
      
      # Si la imagen es escala de grises (matriz 2D), replicar canales
      if (length(dim(img)) == 2) {
        r <- img; g <- img; b <- img
      } else {
        # Si es color (matriz 3D)
        r <- img[,,1]
        g <- img[,,2]
        b <- img[,,3]
      }
      
      features[j, 1] = median(r)
      features[j, 2] = median(g)
      features[j, 3] = median(b)
      
      
    }, error = function(e) {
      cat("Error leyendo:", df_datos$ruta[j], "\n")
    })
  }
  
  # Unir al dataframe y asegurar que la etiqueta es factor
  df_final <- cbind(df_datos, features)
  df_final$etiqueta <- as.factor(df_final$etiqueta)
  
  return(df_final)
}

# Aplicamos la función 
datos_train <- extraer_rgb(datos_train)
datos_test <- extraer_rgb(datos_test)

print(head(datos_train))



```
```{r}
#Preprocesamiento de imagenes
#misma resolucion y rango de valores



```


```{r}
library(ggplot2)
library(tidyr)

# Transformar datos a formato largo para plotear 
datos_long <- pivot_longer(datos_train, cols = c("R_mediana", "G_mediana", "B_mediana"), 
                           names_to = "Feature", values_to = "Valor")

# Plot de Cajas: Compara la distribución de cada canal por etiqueta
ggplot(datos_long, aes(x = Feature, y = Valor, fill = etiqueta)) +
  geom_boxplot() +
  scale_fill_manual(values = c("red", "skyblue"), labels = c("Noche", "Día")) +
  labs(title = "Separación de Clases usando RGB",
       subtitle = "Si las cajas no se tocan, el clasificador será muy bueno",
       y = "Intensidad Mediana (0-1)") +
  theme_minimal()
```
Para la etiqueta "1" (Día), las cajas de R, G y B están mucho más altas (cerca de 0.5 - 1.0) y para "0" (Noche) están muy bajas (cerca de 0.0 - 0.2).

```{r}
#plotear en 3D las caracteristicas RGB medianos, con cada punto segun su etiqueta
library(plotly)
fig <- plot_ly(
  data = datos_train,
  x = ~R_mediana,
  y = ~G_mediana,
  z = ~B_mediana,
  color = ~as.factor(etiqueta),
  colors = c('blue', 'yellow'),
  type = 'scatter3d',
  mode = 'markers'
)
fig <- fig %>% layout(
  scene = list(
    xaxis = list(title = 'R Mediana'),
    yaxis = list(title = 'G Mediana'),
    zaxis = list(title = 'B Mediana')
  ),
  title = 'Distribución de Imágenes por Características RGB Medianas'
)
fig
```
Probamos a entrenar clasificador KNN 
Usamos solo R, G y B.
```{r}
# Seleccionar solo columnas numéricas RGB
cols_rgb <- c("R_mediana", "G_mediana", "B_mediana")

train_x <- datos_train[, cols_rgb]
test_x <- datos_test[, cols_rgb]
train_y <- datos_train$etiqueta
test_y <- datos_test$etiqueta

# Entrenar Random Forest
set.seed(42)
rf_model <- randomForest(x = train_x, y = train_y, ntree = 100)
# Predecir en el conjunto de prueba
predicciones_rf <- predict(rf_model, newdata = test_x)
# Matriz de confusión
cm_rf <- confusionMatrix(predicciones_rf, test_y)
print(cm_rf)
cat("Precisión del modelo Random Forest:", cm_rf$overall['Accuracy'] * 100, "%\n")

```
```{r}
# Probar a extraer caracteristicas del espacio HSV
library(grDevices)
rgb_a_hsv <- function(r, g, b) {
  rgb_matrix <- matrix(c(r, g, b), ncol = 3)
  hsv_matrix <- rgb2hsv(t(rgb_matrix),maxColorValue = 1) #porque los valores ya estan entre 0 y 1
  return(t(hsv_matrix))
}
# Función para extraer características HSV medianas
extraer_hsv <- function(df_datos) {
  features <- matrix(0, nrow = nrow(df_datos), ncol = 3)
  colnames(features) <- c("H_mediana", "S_mediana", "V_mediana")
  
  cat("Extrayendo HSV de", nrow(df_datos), "imágenes...\n")
  
  for (j in 1:nrow(df_datos)) {
    tryCatch({
      img <- readJPEG(df_datos$ruta[j])
      
      if (length(dim(img)) == 2) {
        r <- img; g <- img; b <- img
      } else {
        r <- img[,,1]
        g <- img[,,2]
        b <- img[,,3]
      }
      
      hsv_vals <- rgb_a_hsv(as.vector(r), as.vector(g), as.vector(b))
      
      features[j, 1] = median(hsv_vals[, 1])
      features[j, 2] = median(hsv_vals[, 2])
      features[j, 3] = median(hsv_vals[, 3])

      
    }, error = function(e) {
      cat("Error leyendo:", df_datos$ruta[j], "\n")
    })
  }
  
  df_final <- cbind(df_datos, features)
  df_final$etiqueta <- as.factor(df_final$etiqueta)
  
  return(df_final)
}

# Aplicar la función a los conjuntos de datos
datos_train_hsv <- extraer_hsv(datos_train)
datos_test_hsv <- extraer_hsv(datos_test)
# Seleccionar solo columnas numéricas HSV
cols_hsv <- c("H_mediana", "S_mediana", "V_mediana")
train_x_hsv <- datos_train_hsv[, cols_hsv]
test_x_hsv <- datos_test_hsv[, cols_hsv]
train_y_hsv <- datos_train_hsv$etiqueta
test_y_hsv <- datos_test_hsv$etiqueta
```

```{r}

#Mostrar boxplots de las caracteristicas HSV
datos_long_hsv <- pivot_longer(datos_train_hsv, cols = c("H_mediana", "S_mediana", "V_mediana"), 
                           names_to = "Feature", values_to = "Valor")
ggplot(datos_long_hsv, aes(x = Feature, y = Valor, fill = etiqueta)) +
  geom_boxplot() +
  scale_fill_manual(values = c("red", "skyblue"), labels = c("Noche", "Día")) +
  labs(title = "Separación de Clases usando HSV",
       subtitle = "Si las cajas no se tocan, el clasificador será muy bueno",
       y = "Valor Mediano (0-1)") +
  theme_minimal()
```

```{r}
#plotear en 3D las caracteristicas HSV medianos, con cada punto segun su etiqueta
library(plotly)
fig_hsv <- plot_ly(
  data = datos_train_hsv,
  x = ~H_mediana,
  y = ~S_mediana,
  z = ~V_mediana,
  color = ~as.factor(etiqueta),
  colors = c('blue', 'yellow'),
  type = 'scatter3d',
  mode = 'markers'
)
fig_hsv <- fig_hsv %>% layout(
  scene = list(
    xaxis = list(title = 'H Mediana'),
    yaxis = list(title = 'S Mediana'),
    zaxis = list(title = 'V Mediana')
  ),
  title = 'Distribución de Imágenes por Características HSV Medianas'
)
fig_hsv
```





```{r}
# Entrenar Random Forest con características HSV

set.seed(42)
rf_model_hsv <- randomForest(x = train_x_hsv, y = train_y_hsv, ntree = 100)
# Predecir en el conjunto de prueba
predicciones_rf_hsv <- predict(rf_model_hsv, newdata = test_x_hsv)
# Matriz de confusión
cm_rf_hsv <- confusionMatrix(predicciones_rf_hsv, test_y_hsv)
print(cm_rf_hsv)
cat("Precisión del modelo Random Forest con HSV:", cm_rf_hsv$overall['Accuracy'] * 100, "%\n")
```
```{r}
#Entrenar con todas las caracteristicas RGB + HSV
train_x_todas <- datos_train_hsv[, c("R_mediana", "G_mediana", "B_mediana", "H_mediana", "S_mediana", "V_mediana")]
test_x_todas <- datos_test_hsv[, c("R_mediana", "G_mediana", "B_mediana", "H_mediana", "S_mediana", "V_mediana")]
train_y_todas <- datos_train_hsv$etiqueta
test_y_todas <- datos_test_hsv$etiqueta

set.seed(42)
rf_model_todas <- randomForest(x = train_x_todas, y = train_y_todas, ntree = 100)
# Predecir en el conjunto de prueba
predicciones_rf_todas <- predict(rf_model_todas, newdata = test_x_todas)
# Matriz de confusión
cm_rf_todas <- confusionMatrix(predicciones_rf_todas, test_y_todas)
print(cm_rf_todas)
cat("Precisión del modelo Random Forest con todas las características:", cm_rf_todas$overall['Accuracy'] * 100, "%\n")
```

```{r}
#sacar nombre de imagenes mal clasificadas
mal_clasificadas <- datos_test_hsv[predicciones_rf_todas != test_y_todas, "ruta"]
cat("Imágenes mal clasificadas:\n")
print(mal_clasificadas)
```
```{r}
#nueva caracteristica: filtro de Sobel detector de bordes
library(imager)
extraer_sobel <- function(df_datos) {
  features <- numeric(nrow(df_datos))
  
  cat("Extrayendo características de Sobel de", nrow(df_datos), "imágenes...\n")
  
  for (j in 1:nrow(df_datos)) {
    tryCatch({
      img <- load.image(df_datos$ruta[j])
      img_gray <- grayscale(img)
      #Calcular gradientes --> Sobel es el método por defecto en imager
      # xy indica que queremos derivadas en ambas direcciones
      gradientes <- imgradient(img_gray, "xy")
      
      # Calcular la Magnitud del gradiente con pitagoras
      # gradientes$x es el borde vertical, gradientes$y es el horizontal
      
      magnitud <- sqrt(gradientes$x^2 + gradientes$y^2)
      
      # característica es el promedio de intensidad de los bordes
      features[j] <- mean(magnitud)
      
    }, error = function(e) {
      cat("Error leyendo:", df_datos$ruta[j], "\n")
    })
  }
      
      
  df_final <- cbind(df_datos, Sobel_mean = features)
  df_final$etiqueta <- as.factor(df_final$etiqueta)
  return(df_final)
}


# Aplicar la función a los conjuntos de datos
datos_train_sobel <- extraer_sobel(datos_train_hsv)
datos_test_sobel <- extraer_sobel(datos_test_hsv)
# Entrenar Random Forest con todas las características + Sobel
train_x_sobel <- datos_train_sobel[, c("R_mediana", "G_mediana", "B_mediana", "H_mediana", "S_mediana", "V_mediana", "Sobel_mean")]
test_x_sobel <- datos_test_sobel[, c("R_mediana", "G_mediana", "B_mediana", "H_mediana", "S_mediana", "V_mediana", "Sobel_mean")]
train_y_sobel <- datos_train_sobel$etiqueta
test_y_sobel <- datos_test_sobel$etiqueta
```

```{r}
#sacamos boxplot de la caracteristica Sobel
ggplot(datos_train_sobel, aes(x = etiqueta, y = Sobel_mean, fill = etiqueta)) +
  geom_boxplot() +
  scale_fill_manual(values = c("red", "skyblue"), labels = c("Noche", "Día")) +
  labs(title = "Separación de Clases usando Característica Sobel",
       y = "Valor Medio de Sobel") +
  theme_minimal()

```

```{r}
#entrenar modelo con caracteristicas + Sobel
set.seed(42)
rf_model_sobel <- randomForest(x = train_x_sobel, y = train_y_sobel, ntree = 100)
# Predecir en el conjunto de prueba
predicciones_rf_sobel <- predict(rf_model_sobel, newdata = test_x_sobel)
# Matriz de confusión
cm_rf_sobel <- confusionMatrix(predicciones_rf_sobel, test_y_sobel)
print(cm_rf_sobel)
cat("Precisión del modelo Random Forest con todas las características + Sobel:", cm_rf_sobel$overall['Accuracy'] * 100, "%\n")

#sacar importancia del Random forest para cada caracteristica
importancia <- importance(rf_model_sobel)
print(importancia)
```
$$Luminancia = 0.299 \cdot Rojo + \mathbf{0.587 \cdot Verde} + 0.114 \cdot Azul$$
El canal Verde aporta casi el 60% de la información de brillo de una imagen. 

Probamos a contar el numero de px que superan el 90% del brillo de la imagen, añadiendolo como nueva caracteristica de fuetnes de luz
```{r}
extraer_fuentes_luz <- function(df_datos) {
  features <- numeric(nrow(df_datos))
  
  cat("Extrayendo características de Fuentes de Luz de", nrow(df_datos), "imágenes...\n")
  
  for (j in 1:nrow(df_datos)) {
    tryCatch({
      img <- readJPEG(df_datos$ruta[j])
      
      # if (length(dim(img)) == 2) {
      #   r <- img; g <- img; b <- img
      # } else {
      #   r <- img[,,1]
      #   g <- img[,,2]
      #   b <- img[,,3]
      # }
      # 
      # # Calcular luminancia
      # luminancia <- 0.299 * r + 0.587 * g + 0.114 * b
      
      # 1. Convertir a escala de grises manualmente
      # Si la imagen tiene 3 dimensiones (es a color)
      if (length(dim(img)) == 3) {
        r <- img[,,1]
        g <- img[,,2]
        b <- img[,,3]
        # Fórmula de luminancia (la que tenías comentada)
        img_gray <- 0.299 * r + 0.587 * g + 0.114 * b
      } else {
        # Si ya es escala de grises (2 dimensiones)
        img_gray <- img
      }
      
      # 2. Definir umbral de "luz brillante"
      umbral <- 0.9
      
      # 3. Contar píxeles
      # Esto devuelve la cantidad de píxeles que superan el umbral (puntos blancos)
      features[j] <- sum(img_gray > umbral)
      
    }, error = function(e) {
      cat("Error leyendo:", df_datos$ruta[j], "\n")
    })
  }
  
  df_final <- cbind(df_datos, Fuentes_luz = features)
  df_final$etiqueta <- as.factor(df_final$etiqueta)
  return(df_final)
}
# Aplicar la función a los conjuntos de datos
datos_train_fuentes <- extraer_fuentes_luz(datos_train_sobel)
datos_test_fuentes <- extraer_fuentes_luz(datos_test_sobel)
```   
```{r}
#boxplot de la caracteristica Fuentes de Luz
ggplot(datos_train_fuentes, aes(x = etiqueta, y = Fuentes_luz, fill = etiqueta)) +
  geom_boxplot() +
  scale_fill_manual(values = c("red", "skyblue"), labels = c("Noche", "Día")) +
  labs(title = "Separación de Clases usando Característica Fuentes de Luz",
       y = "Número de Píxeles Brillantes") +
  theme_minimal()
```

```{r}
#entrenar modelo con caracteristicas + Sobel + Fuentes de Luz
train_x_fuentes <- datos_train_fuentes[, c("R_mediana", "G_mediana", "B_mediana", "H_mediana", "S_mediana", "V_mediana", "Sobel_mean", "Fuentes_luz")]
test_x_fuentes <- datos_test_fuentes[, c("R_mediana", "G_mediana", "B_mediana", "H_mediana", "S_mediana", "V_mediana", "Sobel_mean", "Fuentes_luz")]
train_y_fuentes <- datos_train_fuentes$etiqueta
test_y_fuentes <- datos_test_fuentes$etiqueta

set.seed(42)
rf_model_fuentes <- randomForest(x = train_x_fuentes, y = train_y_fuentes, ntree = 100)
# Predecir en el conjunto de prueba
predicciones_rf_fuentes <- predict(rf_model_fuentes, newdata = test_x_fuentes)
# Matriz de confusión
cm_rf_fuentes <- confusionMatrix(predicciones_rf_fuentes, test_y_fuentes)
print(cm_rf_fuentes)
cat("Precisión del modelo Random Forest con todas las características + Sobel + Fuentes de Luz:", cm_rf_fuentes$overall['Accuracy'] * 100, "%\n")

#sacar importancia del Random forest para cada caracteristica
importancia_fuentes <- importance(rf_model_fuentes)
print(importancia_fuentes)
```


Vamos a probar con la entropía de las imágenes.
```{r}
library(entropy)
extraer_entropia <- function(df_datos) {
  features <- numeric(nrow(df_datos))
  
  cat("Extrayendo características de Entropía de", nrow(df_datos), "imágenes...\n")
  
  for (j in 1:nrow(df_datos)) {
    tryCatch({
      img <- load.image(df_datos$ruta[j])
      img_gray <- grayscale(img)
      entropia <- entropy(table(as.numeric(img_gray)))
      features[j] <- entropia
    }, error = function(e) {
      cat("Error leyendo:", df_datos$ruta[j], "\n")
    })
  }

  df_final <- cbind(df_datos, Entropia = features)
  df_final$etiqueta <- as.factor(df_final$etiqueta)
  return(df_final)
}
 
```

```{r}
# Aplicar la función a los conjuntos de datos
datos_train_entropia <- extraer_entropia(datos_train_fuentes)
datos_test_entropia <- extraer_entropia(datos_test_fuentes)
```

```{r}
#entrenar modelo con caracteristicas + Sobel + Fuentes de Luz + Entropía
train_x_entropia <- datos_train_entropia[, c("R_mediana", "G_mediana", "B_mediana", "H_mediana", "S_mediana", "V_mediana", "Sobel_mean", "Fuentes_luz", "Entropia")]
test_x_entropia <- datos_test_entropia[, c("R_mediana", "G_mediana", "B_mediana", "H_mediana", "S_mediana", "V_mediana", "Sobel_mean", "Fuentes_luz", "Entropia")]
train_y_entropia <- datos_train_entropia$etiqueta
test_y_entropia <- datos_test_entropia$etiqueta

set.seed(42)
rf_model_entropia <- randomForest(x = train_x_entropia, y = train_y_entropia, ntree = 100)
# Predecir en el conjunto de prueba
predicciones_rf_entropia <- predict(rf_model_entropia, newdata = test_x_entropia)
# Matriz de confusión
cm_rf_entropia <- confusionMatrix(predicciones_rf_entropia, test_y_entropia)
print(cm_rf_entropia)
cat("Precisión del modelo Random Forest con todas las características + Sobel + Fuentes de Luz + Entropía:", cm_rf_entropia$overall['Accuracy'] * 100, "%\n")

#sacar importancia del Random forest para cada caracteristica
importancia_entropia <- importance(rf_model_entropia)
print(importancia_entropia)
```

