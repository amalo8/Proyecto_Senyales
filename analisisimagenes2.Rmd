---
title: "AnalisisImagenes"
output: html_document
date: "2025-12-27"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(jpeg)
library(class)
library(caret)
library(randomForest)

# Definir la ruta base
ruta_base_imagenes <- "imagenes"

# lectura de las imagenes de noche
ruta_noche <- file.path(ruta_base_imagenes, "nighttime")
archivos_noche <- list.files(
  path = ruta_noche,
  pattern = "\\.jpe?g$",
  full.names = TRUE,
  recursive = FALSE
)

df_noche <- data.frame(
  ruta = archivos_noche,
  etiqueta = 0 # Noche
)


# Leer y etiquetar imágenes del subdirectorio dia

ruta_dia <- file.path(ruta_base_imagenes, "daytime")
archivos_dia <- list.files(
  path = ruta_dia,
  pattern = "\\.jpe?g$",
  full.names = TRUE,
  recursive = FALSE
)

df_dia <- data.frame(
  ruta = archivos_dia,
  etiqueta = 1 # Día
)

# lectura de las imagenes de día

datos_imagenes <- rbind(df_noche, df_dia)


set.seed(42) 

indices_entrenamiento <- createDataPartition(
  y = datos_imagenes$etiqueta,
  p = 0.8,
  list = FALSE 
)

# Crear los conjuntos de datos de TRAIN y TEST
datos_train <- datos_imagenes[indices_entrenamiento, ]
datos_test <- datos_imagenes[-indices_entrenamiento, ]


```

```{r}
extraer_rgb <- function(df_datos) {
  
  # Matriz para R, G, B
  features <- matrix(0, nrow = nrow(df_datos), ncol = 3)
  colnames(features) <- c("R_mediana", "G_mediana", "B_mediana")
  
  cat("Extrayendo RGB de", nrow(df_datos), "imágenes...\n")
  
  for (j in 1:nrow(df_datos)) {
    tryCatch({
      img <- readJPEG(df_datos$ruta[j])
      
      # Si la imagen es escala de grises (matriz 2D), replicar canales
      if (length(dim(img)) == 2) {
        r <- img; g <- img; b <- img
      } else {
        # Si es color (matriz 3D)
        r <- img[,,1]
        g <- img[,,2]
        b <- img[,,3]
      }
      
      features[j, 1] = median(r)
      features[j, 2] = median(g)
      features[j, 3] = median(b)
      
      
    }, error = function(e) {
      cat("Error leyendo:", df_datos$ruta[j], "\n")
    })
  }
  
  # Unir al dataframe y asegurar que la etiqueta es factor
  df_final <- cbind(df_datos, features)
  df_final$etiqueta <- as.factor(df_final$etiqueta)
  
  return(df_final)
}

# Aplicamos la función 
datos_train <- extraer_rgb(datos_train)
datos_test <- extraer_rgb(datos_test)

print(head(datos_train))



```
```{r}
#Preprocesamiento de imagenes
#misma resolucion y rango de valores



```


```{r}
library(ggplot2)
library(tidyr)

# Transformar datos a formato largo para plotear 
datos_long <- pivot_longer(datos_train, cols = c("R_mediana", "G_mediana", "B_mediana"), 
                           names_to = "Feature", values_to = "Valor")

# Plot de Cajas: Compara la distribución de cada canal por etiqueta
ggplot(datos_long, aes(x = Feature, y = Valor, fill = etiqueta)) +
  geom_boxplot() +
  scale_fill_manual(values = c("red", "skyblue"), labels = c("Noche", "Día")) +
  labs(title = "Separación de Clases usando RGB",
       subtitle = "Si las cajas no se tocan, el clasificador será muy bueno",
       y = "Intensidad Mediana (0-1)") +
  theme_minimal()
```
Para la etiqueta "1" (Día), las cajas de R, G y B están mucho más altas (cerca de 0.5 - 1.0) y para "0" (Noche) están muy bajas (cerca de 0.0 - 0.2).

```{r}
#plotear en 3D las caracteristicas RGB medianos, con cada punto segun su etiqueta
library(plotly)
fig <- plot_ly(
  data = datos_train,
  x = ~R_mediana,
  y = ~G_mediana,
  z = ~B_mediana,
  color = ~as.factor(etiqueta),
  colors = c('blue', 'yellow'),
  type = 'scatter3d',
  mode = 'markers'
)
fig <- fig %>% layout(
  scene = list(
    xaxis = list(title = 'R Mediana'),
    yaxis = list(title = 'G Mediana'),
    zaxis = list(title = 'B Mediana')
  ),
  title = 'Distribución de Imágenes por Características RGB Medianas'
)
fig
```
Probamos a entrenar clasificador KNN 
Usamos solo R, G y B.
```{r}
# Seleccionar solo columnas numéricas RGB
cols_rgb <- c("R_mediana", "G_mediana", "B_mediana")

train_x <- datos_train[, cols_rgb]
test_x <- datos_test[, cols_rgb]
train_y <- datos_train$etiqueta
test_y <- datos_test$etiqueta

# Entrenar Random Forest
set.seed(42)
rf_model <- randomForest(x = train_x, y = train_y, ntree = 100)
# Predecir en el conjunto de prueba
predicciones_rf <- predict(rf_model, newdata = test_x)
# Matriz de confusión
cm_rf <- confusionMatrix(predicciones_rf, test_y)
print(cm_rf)
cat("Precisión del modelo Random Forest:", cm_rf$overall['Accuracy'] * 100, "%\n")

```
```{r}
# Probar a extraer caracteristicas del espacio HSV
library(grDevices)
rgb_a_hsv <- function(r, g, b) {
  rgb_matrix <- matrix(c(r, g, b), ncol = 3)
  hsv_matrix <- rgb2hsv(t(rgb_matrix),maxColorValue = 1) #porque los valores ya estan entre 0 y 1
  return(t(hsv_matrix))
}
# Función para extraer características HSV medianas
extraer_hsv <- function(df_datos) {
  features <- matrix(0, nrow = nrow(df_datos), ncol = 3)
  colnames(features) <- c("H_mediana", "S_mediana", "V_mediana")
  
  cat("Extrayendo HSV de", nrow(df_datos), "imágenes...\n")
  
  for (j in 1:nrow(df_datos)) {
    tryCatch({
      img <- readJPEG(df_datos$ruta[j])
      
      if (length(dim(img)) == 2) {
        r <- img; g <- img; b <- img
      } else {
        r <- img[,,1]
        g <- img[,,2]
        b <- img[,,3]
      }
      
      hsv_vals <- rgb_a_hsv(as.vector(r), as.vector(g), as.vector(b))
      
      features[j, 1] = median(hsv_vals[, 1])
      features[j, 2] = median(hsv_vals[, 2])
      features[j, 3] = median(hsv_vals[, 3])

      
    }, error = function(e) {
      cat("Error leyendo:", df_datos$ruta[j], "\n")
    })
  }
  
  df_final <- cbind(df_datos, features)
  df_final$etiqueta <- as.factor(df_final$etiqueta)
  
  return(df_final)
}

# Aplicar la función a los conjuntos de datos
datos_train_hsv <- extraer_hsv(datos_train)
datos_test_hsv <- extraer_hsv(datos_test)
# Seleccionar solo columnas numéricas HSV
cols_hsv <- c("H_mediana", "S_mediana", "V_mediana")
train_x_hsv <- datos_train_hsv[, cols_hsv]
test_x_hsv <- datos_test_hsv[, cols_hsv]
train_y_hsv <- datos_train_hsv$etiqueta
test_y_hsv <- datos_test_hsv$etiqueta
```

```{r}

#Mostrar boxplots de las caracteristicas HSV
datos_long_hsv <- pivot_longer(datos_train_hsv, cols = c("H_mediana", "S_mediana", "V_mediana"), 
                           names_to = "Feature", values_to = "Valor")
ggplot(datos_long_hsv, aes(x = Feature, y = Valor, fill = etiqueta)) +
  geom_boxplot() +
  scale_fill_manual(values = c("red", "skyblue"), labels = c("Noche", "Día")) +
  labs(title = "Separación de Clases usando HSV",
       subtitle = "Si las cajas no se tocan, el clasificador será muy bueno",
       y = "Valor Mediano (0-1)") +
  theme_minimal()
```

```{r}
#plotear en 3D las caracteristicas HSV medianos, con cada punto segun su etiqueta
library(plotly)
fig_hsv <- plot_ly(
  data = datos_train_hsv,
  x = ~H_mediana,
  y = ~S_mediana,
  z = ~V_mediana,
  color = ~as.factor(etiqueta),
  colors = c('blue', 'yellow'),
  type = 'scatter3d',
  mode = 'markers'
)
fig_hsv <- fig_hsv %>% layout(
  scene = list(
    xaxis = list(title = 'H Mediana'),
    yaxis = list(title = 'S Mediana'),
    zaxis = list(title = 'V Mediana')
  ),
  title = 'Distribución de Imágenes por Características HSV Medianas'
)
fig_hsv
```





```{r}
# Entrenar Random Forest con características HSV

set.seed(42)
rf_model_hsv <- randomForest(x = train_x_hsv, y = train_y_hsv, ntree = 100)
# Predecir en el conjunto de prueba
predicciones_rf_hsv <- predict(rf_model_hsv, newdata = test_x_hsv)
# Matriz de confusión
cm_rf_hsv <- confusionMatrix(predicciones_rf_hsv, test_y_hsv)
print(cm_rf_hsv)
cat("Precisión del modelo Random Forest con HSV:", cm_rf_hsv$overall['Accuracy'] * 100, "%\n")
```
```{r}
#Entrenar con todas las caracteristicas RGB + HSV
train_x_todas <- datos_train_hsv[, c("R_mediana", "G_mediana", "B_mediana", "H_mediana", "S_mediana", "V_mediana")]
test_x_todas <- datos_test_hsv[, c("R_mediana", "G_mediana", "B_mediana", "H_mediana", "S_mediana", "V_mediana")]
train_y_todas <- datos_train_hsv$etiqueta
test_y_todas <- datos_test_hsv$etiqueta

set.seed(42)
rf_model_todas <- randomForest(x = train_x_todas, y = train_y_todas, ntree = 100)
# Predecir en el conjunto de prueba
predicciones_rf_todas <- predict(rf_model_todas, newdata = test_x_todas)
# Matriz de confusión
cm_rf_todas <- confusionMatrix(predicciones_rf_todas, test_y_todas)
print(cm_rf_todas)
cat("Precisión del modelo Random Forest con todas las características:", cm_rf_todas$overall['Accuracy'] * 100, "%\n")
```

```{r}
#sacar nombre de imagenes mal clasificadas
mal_clasificadas <- datos_test_hsv[predicciones_rf_todas != test_y_todas, "ruta"]
cat("Imágenes mal clasificadas:\n")
print(mal_clasificadas)
```
```{r}
#nueva caracteristica: filtro de Sobel detector de bordes
library(imager)
extraer_sobel <- function(df_datos) {
  features <- numeric(nrow(df_datos))
  
  cat("Extrayendo características de Sobel de", nrow(df_datos), "imágenes...\n")
  
  for (j in 1:nrow(df_datos)) {
    tryCatch({
      img <- load.image(df_datos$ruta[j])
      img_gray <- grayscale(img)
      #Calcular gradientes --> Sobel es el método por defecto en imager
      # xy indica que queremos derivadas en ambas direcciones
      gradientes <- imgradient(img_gray, "xy")
      
      # Calcular la Magnitud del gradiente con pitagoras
      # gradientes$x es el borde vertical, gradientes$y es el horizontal
      
      magnitud <- sqrt(gradientes$x^2 + gradientes$y^2)
      
      # característica es el promedio de intensidad de los bordes
      features[j] <- mean(magnitud)
      
    }, error = function(e) {
      cat("Error leyendo:", df_datos$ruta[j], "\n")
    })
  }
      
      
  df_final <- cbind(df_datos, Sobel_mean = features)
  df_final$etiqueta <- as.factor(df_final$etiqueta)
  return(df_final)
}


# Aplicar la función a los conjuntos de datos
datos_train_sobel <- extraer_sobel(datos_train_hsv)
datos_test_sobel <- extraer_sobel(datos_test_hsv)
# Entrenar Random Forest con todas las características + Sobel
train_x_sobel <- datos_train_sobel[, c("R_mediana", "G_mediana", "B_mediana", "H_mediana", "S_mediana", "V_mediana", "Sobel_mean")]
test_x_sobel <- datos_test_sobel[, c("R_mediana", "G_mediana", "B_mediana", "H_mediana", "S_mediana", "V_mediana", "Sobel_mean")]
train_y_sobel <- datos_train_sobel$etiqueta
test_y_sobel <- datos_test_sobel$etiqueta
```

```{r}
#sacamos boxplot de la caracteristica Sobel
ggplot(datos_train_sobel, aes(x = etiqueta, y = Sobel_mean, fill = etiqueta)) +
  geom_boxplot() +
  scale_fill_manual(values = c("red", "skyblue"), labels = c("Noche", "Día")) +
  labs(title = "Separación de Clases usando Característica Sobel",
       y = "Valor Medio de Sobel") +
  theme_minimal()

```

```{r}
#entrenar modelo con caracteristicas + Sobel
set.seed(42)
rf_model_sobel <- randomForest(x = train_x_sobel, y = train_y_sobel, ntree = 100)
# Predecir en el conjunto de prueba
predicciones_rf_sobel <- predict(rf_model_sobel, newdata = test_x_sobel)
# Matriz de confusión
cm_rf_sobel <- confusionMatrix(predicciones_rf_sobel, test_y_sobel)
print(cm_rf_sobel)
cat("Precisión del modelo Random Forest con todas las características + Sobel:", cm_rf_sobel$overall['Accuracy'] * 100, "%\n")

#sacar importancia del Random forest para cada caracteristica
importancia <- importance(rf_model_sobel)
print(importancia)
```
$$Luminancia = 0.299 \cdot Rojo + \mathbf{0.587 \cdot Verde} + 0.114 \cdot Azul$$
El canal Verde aporta casi el 60% de la información de brillo de una imagen. 

Probamos a contar el numero de px que superan el 90% del brillo de la imagen, añadiendolo como nueva caracteristica de fuetnes de luz
```{r}
extraer_fuentes_luz <- function(df_datos) {
  features <- numeric(nrow(df_datos))
  
  cat("Extrayendo características de Fuentes de Luz de", nrow(df_datos), "imágenes...\n")
  
  for (j in 1:nrow(df_datos)) {
    tryCatch({
      img <- readJPEG(df_datos$ruta[j])
      
      # if (length(dim(img)) == 2) {
      #   r <- img; g <- img; b <- img
      # } else {
      #   r <- img[,,1]
      #   g <- img[,,2]
      #   b <- img[,,3]
      # }
      # 
      # # Calcular luminancia
      # luminancia <- 0.299 * r + 0.587 * g + 0.114 * b
      
      # 1. Convertir a escala de grises manualmente
      # Si la imagen tiene 3 dimensiones (es a color)
      if (length(dim(img)) == 3) {
        r <- img[,,1]
        g <- img[,,2]
        b <- img[,,3]
        # Fórmula de luminancia (la que tenías comentada)
        img_gray <- 0.299 * r + 0.587 * g + 0.114 * b
      } else {
        # Si ya es escala de grises (2 dimensiones)
        img_gray <- img
      }
      
      # 2. Definir umbral de "luz brillante"
      umbral <- 0.9
      
      # 3. Contar píxeles
      # Esto devuelve la cantidad de píxeles que superan el umbral (puntos blancos)
      features[j] <- sum(img_gray > umbral)
      
    }, error = function(e) {
      cat("Error leyendo:", df_datos$ruta[j], "\n")
    })
  }
  
  df_final <- cbind(df_datos, Fuentes_luz = features)
  df_final$etiqueta <- as.factor(df_final$etiqueta)
  return(df_final)
}
# Aplicar la función a los conjuntos de datos
datos_train_fuentes <- extraer_fuentes_luz(datos_train_sobel)
datos_test_fuentes <- extraer_fuentes_luz(datos_test_sobel)
```   
```{r}
#boxplot de la caracteristica Fuentes de Luz
ggplot(datos_train_fuentes, aes(x = etiqueta, y = Fuentes_luz, fill = etiqueta)) +
  geom_boxplot() +
  scale_fill_manual(values = c("red", "skyblue"), labels = c("Noche", "Día")) +
  labs(title = "Separación de Clases usando Característica Fuentes de Luz",
       y = "Número de Píxeles Brillantes") +
  theme_minimal()
```

```{r}
#entrenar modelo con caracteristicas + Sobel + Fuentes de Luz
train_x_fuentes <- datos_train_fuentes[, c("R_mediana", "G_mediana", "B_mediana", "H_mediana", "S_mediana", "V_mediana", "Sobel_mean", "Fuentes_luz")]
test_x_fuentes <- datos_test_fuentes[, c("R_mediana", "G_mediana", "B_mediana", "H_mediana", "S_mediana", "V_mediana", "Sobel_mean", "Fuentes_luz")]
train_y_fuentes <- datos_train_fuentes$etiqueta
test_y_fuentes <- datos_test_fuentes$etiqueta

set.seed(42)
rf_model_fuentes <- randomForest(x = train_x_fuentes, y = train_y_fuentes, ntree = 100)
# Predecir en el conjunto de prueba
predicciones_rf_fuentes <- predict(rf_model_fuentes, newdata = test_x_fuentes)
# Matriz de confusión
cm_rf_fuentes <- confusionMatrix(predicciones_rf_fuentes, test_y_fuentes)
print(cm_rf_fuentes)
cat("Precisión del modelo Random Forest con todas las características + Sobel + Fuentes de Luz:", cm_rf_fuentes$overall['Accuracy'] * 100, "%\n")

#sacar importancia del Random forest para cada caracteristica
importancia_fuentes <- importance(rf_model_fuentes)
print(importancia_fuentes)
```


Vamos a probar con la entropía de las imágenes.
```{r}
library(entropy)
extraer_entropia <- function(df_datos) {
  features <- numeric(nrow(df_datos))
  
  cat("Extrayendo características de Entropía de", nrow(df_datos), "imágenes...\n")
  
  for (j in 1:nrow(df_datos)) {
    tryCatch({
      img <- load.image(df_datos$ruta[j])
      img_gray <- grayscale(img)
      entropia <- entropy(table(as.numeric(img_gray)))
      features[j] <- entropia
    }, error = function(e) {
      cat("Error leyendo:", df_datos$ruta[j], "\n")
    })
  }

  df_final <- cbind(df_datos, Entropia = features)
  df_final$etiqueta <- as.factor(df_final$etiqueta)
  return(df_final)
}
 
```

```{r}
# Aplicar la función a los conjuntos de datos
datos_train_entropia <- extraer_entropia(datos_train_fuentes)
datos_test_entropia <- extraer_entropia(datos_test_fuentes)
```

```{r}
#entrenar modelo con caracteristicas + Sobel + Fuentes de Luz + Entropía
train_x_entropia <- datos_train_entropia[, c("R_mediana", "G_mediana", "B_mediana", "H_mediana", "S_mediana", "V_mediana", "Sobel_mean", "Fuentes_luz", "Entropia")]
test_x_entropia <- datos_test_entropia[, c("R_mediana", "G_mediana", "B_mediana", "H_mediana", "S_mediana", "V_mediana", "Sobel_mean", "Fuentes_luz", "Entropia")]
train_y_entropia <- datos_train_entropia$etiqueta
test_y_entropia <- datos_test_entropia$etiqueta

set.seed(42)
rf_model_entropia <- randomForest(x = train_x_entropia, y = train_y_entropia, ntree = 100)
# Predecir en el conjunto de prueba
predicciones_rf_entropia <- predict(rf_model_entropia, newdata = test_x_entropia)
# Matriz de confusión
cm_rf_entropia <- confusionMatrix(predicciones_rf_entropia, test_y_entropia)
print(cm_rf_entropia)
cat("Precisión del modelo Random Forest con todas las características + Sobel + Fuentes de Luz + Entropía:", cm_rf_entropia$overall['Accuracy'] * 100, "%\n")

#sacar importancia del Random forest para cada caracteristica
importancia_entropia <- importance(rf_model_entropia)
print(importancia_entropia)
```

Característica mide el porcentaje de píxeles en la imagen cuya luminancia es muy baja (V < 0.1).
```{r}
# nueva caracteristica: porcentaje de pixeles oscuros (luminancia < 0.1)
extraer_pixeles_oscuros <- function(df_datos) {
  features <- numeric(nrow(df_datos))
  for (j in 1:nrow(df_datos)) {
    tryCatch({
      img <- readJPEG(df_datos$ruta[j])
      if (length(dim(img)) == 3) {
        r <- img[,,1]
        g <- img[,,2]
        b <- img[,,3]
        img_gray <- 0.299 * r + 0.587 * g + 0.114 * b
      } else {
        img_gray <- img
      }
      total_pixeles <- length(img_gray)
      pixeles_oscuros <- sum(img_gray < 0.1)
      features[j] <- (pixeles_oscuros / total_pixeles) * 100
    }, error = function(e) {
      cat("Error leyendo:", df_datos$ruta[j], "\n")
    })
  }
  df_final <- cbind(df_datos, Pixeles_oscuros = features)
  df_final$etiqueta <- as.factor(df_final$etiqueta)
  return(df_final)
}
```

```{r}
# Aplicar la función a los conjuntos de datos
datos_train_final <- extraer_pixeles_oscuros(datos_train_entropia)
datos_test_final <- extraer_pixeles_oscuros(datos_test_entropia)
```

```{r}
#entrenar modelo con todas las caracteristicas + Pixeles oscuros
train_x_final <- datos_train_final[, c("R_mediana", "G_mediana", "B_mediana", "H_mediana", "S_mediana", "V_mediana", "Sobel_mean", "Fuentes_luz", "Entropia", "Pixeles_oscuros")]
test_x_final <- datos_test_final[, c("R_mediana", "G_mediana", "B_mediana", "H_mediana", "S_mediana", "V_mediana", "Sobel_mean", "Fuentes_luz", "Entropia", "Pixeles_oscuros")]
train_y_final <- datos_train_final$etiqueta
test_y_final <- datos_test_final$etiqueta

set.seed(42)
rf_model_final <- randomForest(x = train_x_final, y = train_y_final, ntree = 100)
# Predecir en el conjunto de prueba
predicciones_rf_final <- predict(rf_model_final, newdata = test_x_final)
# Matriz de confusión
cm_rf_final <- confusionMatrix(predicciones_rf_final, test_y_final)
print(cm_rf_final)
cat("Precisión del modelo Random Forest con todas las características + Pixeles oscuros:", cm_rf_final$overall['Accuracy'] * 100, "%\n")

#sacar importancia del Random forest para cada caracteristica
importancia_final <- importance(rf_model_final)
print(importancia_final)
```

```{r}
# nueva caracteristica: rango dinamico de V (máximo - mínimo)
extraer_rango_dinamico_V <- function(df_datos) {
  features <- numeric(nrow(df_datos))
  for (j in 1:nrow(df_datos)) {
    tryCatch({
      img <- readJPEG(df_datos$ruta[j])
      if (length(dim(img)) == 3) {
        r <- img[,,1]
        g <- img[,,2]
        b <- img[,,3]
        hsv_vals <- rgb_a_hsv(as.vector(r), as.vector(g), as.vector(b))
        V_channel <- matrix(hsv_vals[, 3], nrow = nrow(r), ncol = ncol(r))
      } else {
        V_channel <- img
      }
      features[j] <- max(V_channel) - min(V_channel)
    }, error = function(e) {
      cat("Error leyendo:", df_datos$ruta[j], "\n")
    })
  }
  df_final <- cbind(df_datos, Rango_dinamico_V = features)
  df_final$etiqueta <- as.factor(df_final$etiqueta)
  return(df_final)
}
```

```{r}
# Aplicar la función a los conjuntos de datos
datos_train_rango <- extraer_rango_dinamico_V(datos_train_final)
datos_test_rango <- extraer_rango_dinamico_V(datos_test_final)
```

```{r}
#entrenar modelo con todas las caracteristicas + Rango dinamico de V
train_x_rango <- datos_train_rango[, c("R_mediana", "G_mediana", "B_mediana", "H_mediana", "S_mediana", "V_mediana", "Sobel_mean", "Fuentes_luz", "Entropia", "Pixeles_oscuros", "Rango_dinamico_V")]
test_x_rango <- datos_test_rango[, c("R_mediana", "G_mediana", "B_mediana", "H_mediana", "S_mediana", "V_mediana", "Sobel_mean", "Fuentes_luz", "Entropia", "Pixeles_oscuros", "Rango_dinamico_V")]
train_y_rango <- datos_train_rango$etiqueta
test_y_rango <- datos_test_rango$etiqueta

set.seed(42)
rf_model_rango <- randomForest(x = train_x_rango, y = train_y_rango, ntree = 100)
# Predecir en el conjunto de prueba
predicciones_rf_rango <- predict(rf_model_rango, newdata = test_x_rango)
# Matriz de confusión
cm_rf_rango <- confusionMatrix(predicciones_rf_rango, test_y_rango)
print(cm_rf_rango)
cat("Precisión del modelo Random Forest con todas las características + Rango dinámico de V:", cm_rf_rango$overall['Accuracy'] * 100, "%\n")

#sacar importancia del Random forest para cada caracteristica
importancia_rango <- importance(rf_model_rango)
print(importancia_rango)
```

Característica que mide la luminancia promedio de la imagen después de aplicar un filtro pasobajo gaussiano sobre el canal V
```{r}
# nueva caracteristica: aplicar filtro pasobajo (blur) gaussiano y calcular la media de V
extraer_blur_V <- function(df_datos) {
  features <- numeric(nrow(df_datos))
  for (j in 1:nrow(df_datos)) {
    tryCatch({
      img <- readJPEG(df_datos$ruta[j])
      if (length(dim(img)) == 3) {
        r <- img[,,1]
        g <- img[,,2]
        b <- img[,,3]
        hsv_vals <- rgb_a_hsv(as.vector(r), as.vector(g), as.vector(b))
        V_channel <- matrix(hsv_vals[, 3], nrow = nrow(r), ncol = ncol(r))
      } else {
        V_channel <- img
      }
      # Aplicar filtro gaussiano
      V_blurred <- imager::isoblur(as.cimg(V_channel), sigma = 2)
      features[j] <- mean(V_blurred)
    }, error = function(e) {
      cat("Error leyendo:", df_datos$ruta[j], "\n")
    })
  }
  df_final <- cbind(df_datos, V_blurred_mean = features)
  df_final$etiqueta <- as.factor(df_final$etiqueta)
  return(df_final)
}
```

```{r}
# Aplicar la función a los conjuntos de datos
datos_train_blur <- extraer_blur_V(datos_train_rango)
datos_test_blur <- extraer_blur_V(datos_test_rango)
```

```{r}
#entrenar modelo con todas las caracteristicas + V blur quitando rango dinamico de V
train_x_blur <- datos_train_blur[, c("R_mediana", "G_mediana", "B_mediana", "H_mediana", "S_mediana", "V_mediana", "Sobel_mean", "Fuentes_luz", "Entropia", "Pixeles_oscuros", "V_blurred_mean")]
test_x_blur <- datos_test_blur[, c("R_mediana", "G_mediana", "B_mediana", "H_mediana", "S_mediana", "V_mediana", "Sobel_mean", "Fuentes_luz", "Entropia", "Pixeles_oscuros", "V_blurred_mean")]
train_y_blur <- datos_train_blur$etiqueta
test_y_blur <- datos_test_blur$etiqueta

set.seed(42)
rf_model_blur <- randomForest(x = train_x_blur, y = train_y_blur, ntree = 100)
# Predecir en el conjunto de prueba
predicciones_rf_blur <- predict(rf_model_blur, newdata = test_x_blur)
# Matriz de confusión
cm_rf_blur <- confusionMatrix(predicciones_rf_blur, test_y_blur)
print(cm_rf_blur)
cat("Precisión del modelo Random Forest con todas las características + V blur:", cm_rf_blur$overall['Accuracy'] * 100, "%\n")

importancia_blur <- importance(rf_model_blur)
print(importancia_blur)
```
```{r}
# nueva caracteristica: desviacion estandar de V
extraer_sd_V <- function(df_datos) {
  features <- numeric(nrow(df_datos))
  for (j in 1:nrow(df_datos)) {
    tryCatch({
      img <- readJPEG(df_datos$ruta[j])
      if (length(dim(img)) == 3) {
        r <- img[,,1]
        g <- img[,,2]
        b <- img[,,3]
        hsv_vals <- rgb_a_hsv(as.vector(r), as.vector(g), as.vector(b))
        V_channel <- matrix(hsv_vals[, 3], nrow = nrow(r), ncol = ncol(r))
      } else {
        V_channel <- img
      }
      features[j] <- sd(as.vector(V_channel))
    }, error = function(e) {
      cat("Error leyendo:", df_datos$ruta[j], "\n")
    })
  }
  df_final <- cbind(df_datos, SD_V = features)
  df_final$etiqueta <- as.factor(df_final$etiqueta)
  return(df_final)
}
```

```{r}
# Aplicar la función a los conjuntos de datos
datos_train_sd <- extraer_sd_V(datos_train_blur)
datos_test_sd <- extraer_sd_V(datos_test_blur)
```

```{r}
#entrenar modelo con todas las caracteristicas + SD de V
train_x_sd <- datos_train_sd[, c("R_mediana", "G_mediana", "B_mediana", "H_mediana", "S_mediana", "V_mediana", "Sobel_mean", "Fuentes_luz", "Entropia", "Pixeles_oscuros", "V_blurred_mean", "SD_V")]
test_x_sd <- datos_test_sd[, c("R_mediana", "G_mediana", "B_mediana", "H_mediana", "S_mediana", "V_mediana", "Sobel_mean", "Fuentes_luz", "Entropia", "Pixeles_oscuros", "V_blurred_mean", "SD_V")]
train_y_sd <- datos_train_sd$etiqueta
test_y_sd <- datos_test_sd$etiqueta

set.seed(42)
rf_model_sd <- randomForest(x = train_x_sd, y = train_y_sd, ntree = 100)
# Predecir en el conjunto de prueba
predicciones_rf_sd <- predict(rf_model_sd, newdata = test_x_sd)
# Matriz de confusión
cm_rf_sd <- confusionMatrix(predicciones_rf_sd, test_y_sd)
print(cm_rf_sd)
cat("Precisión del modelo Random Forest con todas las características + SD de V:", cm_rf_sd$overall['Accuracy'] * 100, "%\n")

importancia_sd <- importance(rf_model_sd)
print(importancia_sd)
```

Añadimos sunrise para probar a ver como funciona
```{r}
# Añadimos una clase: sunrise
# lectura de las imagenes de sunrise
ruta_sunrise <- file.path(ruta_base_imagenes, "sunrise")
archivos_sunrise <- list.files(
  path = ruta_sunrise,
  pattern = "\\.jpe?g$",
  full.names = TRUE,
  recursive = FALSE
)
df_sunrise <- data.frame(
  ruta = archivos_sunrise,
  etiqueta = 2 # Sunrise
)
# Unir con los datos existentes
datos_imagenes_multi <- rbind(datos_imagenes, df_sunrise)
set.seed(42)
indices_entrenamiento_multi <- createDataPartition(
  y = datos_imagenes_multi$etiqueta,
  p = 0.8,
  list = FALSE 
)
# Crear los conjuntos de datos de TRAIN y TEST
datos_train_multi <- datos_imagenes_multi[indices_entrenamiento_multi, ]
datos_test_multi <- datos_imagenes_multi[-indices_entrenamiento_multi, ]
```

```{r}
# Aplicamos el modelo de extracción de características a los nuevos conjuntos (hasta la carcaterística de pixeles oscuros)
datos_train_multi <- extraer_rgb(datos_train_multi)
datos_train_multi <- extraer_hsv(datos_train_multi)
datos_train_multi <- extraer_sobel(datos_train_multi)
datos_train_multi <- extraer_fuentes_luz(datos_train_multi)
datos_train_multi <- extraer_entropia(datos_train_multi)
datos_train_multi <- extraer_pixeles_oscuros(datos_train_multi)
datos_test_multi <- extraer_rgb(datos_test_multi)
datos_test_multi <- extraer_hsv(datos_test_multi)
datos_test_multi <- extraer_sobel(datos_test_multi)
datos_test_multi <- extraer_fuentes_luz(datos_test_multi)
datos_test_multi <- extraer_entropia(datos_test_multi)
datos_test_multi <- extraer_pixeles_oscuros(datos_test_multi)

#entrenar modelo hasta la carcateristica de pixeles oscuros
train_x_multi <- datos_train_multi[, c("R_mediana", "G_mediana", "B_mediana", "H_mediana", "S_mediana", "V_mediana", "Sobel_mean", "Fuentes_luz", "Entropia", "Pixeles_oscuros")]
test_x_multi <- datos_test_multi[, c("R_mediana", "G_mediana", "B_mediana", "H_mediana", "S_mediana", "V_mediana", "Sobel_mean", "Fuentes_luz", "Entropia", "Pixeles_oscuros")]
train_y_multi <- datos_train_multi$etiqueta
test_y_multi <- datos_test_multi$etiqueta

set.seed(42)
rf_model_multi <- randomForest(x = train_x_multi, y = train_y_multi, ntree = 100)
# Predecir en el conjunto de prueba
predicciones_rf_multi <- predict(rf_model_multi, newdata = test_x_multi)
# Matriz de confusión
cm_rf_multi <- confusionMatrix(predicciones_rf_multi, test_y_multi)
print(cm_rf_multi)
cat("Precisión del modelo Random Forest con todas las características para 3 clases (Día, Noche, Amanecer):", cm_rf_multi$overall['Accuracy'] * 100, "%\n")
#sacar importancia del Random forest para cada caracteristica
importancia_multi <- importance(rf_model_multi)
print(importancia_multi)
```
Característica que mide el porcentaje de píxeles de la imagen cuyo tono (H en HSV) corresponde a colores cálidos
```{r}
# nueva caracterisica: porcentaje de tonos cálidos (H entre 0 y 60 grados)
extraer_tonos_calidos <- function(df_datos) {
  features <- numeric(nrow(df_datos))
  for (j in 1:nrow(df_datos)) {
    tryCatch({
      img <- readJPEG(df_datos$ruta[j])
      if (length(dim(img)) == 3) {
        r <- img[,,1]
        g <- img[,,2]
        b <- img[,,3]
        hsv_vals <- rgb_a_hsv(as.vector(r), as.vector(g), as.vector(b))
        H_channel <- matrix(hsv_vals[, 1] * 360, nrow = nrow(r), ncol = ncol(r)) # Convertir a grados
      } else {
        H_channel <- matrix(0, nrow = nrow(img), ncol = ncol(img)) # Asumir 0 si es escala de grises
      }
      total_pixeles <- length(H_channel)
      tonos_calidos <- sum(H_channel >= 0 & H_channel <= 60)
      features[j] <- (tonos_calidos / total_pixeles) * 100
    }, error = function(e) {
      cat("Error leyendo:", df_datos$ruta[j], "\n")
    })
  }
  df_final <- cbind(df_datos, Tonos_calidos = features)
  df_final$etiqueta <- as.factor(df_final$etiqueta)
  return(df_final)
}
```

```{r}
# Aplicar la función a los conjuntos de datos
datos_train_multi_tonos <- extraer_tonos_calidos(datos_train_multi)
datos_test_multi_tonos <- extraer_tonos_calidos(datos_test_multi)
```

```{r}
#entrenar modelo con todas las caracteristicas hasta pixeles oscuros + Tonos cálidos
train_x_multi_tonos <- datos_train_multi_tonos[, c("R_mediana", "G_mediana", "B_mediana", "H_mediana", "S_mediana", "V_mediana", "Sobel_mean", "Fuentes_luz", "Entropia", "Pixeles_oscuros", "Tonos_calidos")]
test_x_multi_tonos <- datos_test_multi_tonos[, c("R_mediana", "G_mediana", "B_mediana", "H_mediana", "S_mediana", "V_mediana", "Sobel_mean", "Fuentes_luz", "Entropia", "Pixeles_oscuros", "Tonos_calidos")]
train_y_multi_tonos <- datos_train_multi_tonos$etiqueta
test_y_multi_tonos <- datos_test_multi_tonos$etiqueta

set.seed(42)
rf_model_multi_tonos <- randomForest(x = train_x_multi_tonos, y = train_y_multi_tonos, ntree = 100)
# Predecir en el conjunto de prueba
predicciones_rf_multi_tonos <- predict(rf_model_multi_tonos, newdata = test_x_multi_tonos)
# Matriz de confusión
cm_rf_multi_tonos <- confusionMatrix(predicciones_rf_multi_tonos, test_y_multi_tonos)
print(cm_rf_multi_tonos)
cat("Precisión del modelo Random Forest con todas las características + Tonos cálidos para 3 clases (Día, Noche, Amanecer):", cm_rf_multi_tonos$overall['Accuracy'] * 100, "%\n")

#sacar importancia del Random forest para cada caracteristica
importancia_multi_tonos <- importance(rf_model_multi_tonos)
print(importancia_multi_tonos)
```

Variación vertical promedio de color (H) y brillo (V) en la imagen.
```{r}
# nueva caracteistica: gradientes verticales de h y v
extraer_gradientes_hv <- function(df_datos) {
  features_H <- numeric(nrow(df_datos))
  features_V <- numeric(nrow(df_datos))
  for (j in 1:nrow(df_datos)) {
    tryCatch({
      img <- readJPEG(df_datos$ruta[j])
      if (length(dim(img)) == 3) {
        r <- img[,,1]
        g <- img[,,2]
        b <- img[,,3]
        hsv_vals <- rgb_a_hsv(as.vector(r), as.vector(g), as.vector(b))
        H_channel <- matrix(hsv_vals[, 1], nrow = nrow(r), ncol = ncol(r))
        V_channel <- matrix(hsv_vals[, 3], nrow = nrow(r), ncol = ncol(r))
      } else {
        H_channel <- matrix(0, nrow = nrow(img), ncol = ncol(img))
        V_channel <- matrix(0, nrow = nrow(img), ncol = ncol(img))
      }
      # Calcular gradiente vertical usando diferencias finitas
      gradiente_H <- abs(diff(H_channel, differences = 1, axis = 1))
      gradiente_V <- abs(diff(V_channel, differences = 1, axis = 1))
      features_H[j] <- mean(gradiente_H, na.rm = TRUE)
      features_V[j] <- mean(gradiente_V, na.rm = TRUE)
    }, error = function(e) {
      cat("Error leyendo:", df_datos$ruta[j], "\n")
    })
  }
  df_final <- cbind(df_datos, Gradiente_H = features_H, Gradiente_V = features_V)
  df_final$etiqueta <- as.factor(df_final$etiqueta)
  return(df_final)
}
```

```{r}
# Aplicar la función a los conjuntos de datos
datos_train_multi_gradientes <- extraer_gradientes_hv(datos_train_multi_tonos)
datos_test_multi_gradientes <- extraer_gradientes_hv(datos_test_multi_tonos)
```

```{r}
#entrenar modelo con todas las caracteristicas hasta tonos cálidos + Gradientes H y V
train_x_multi_gradientes <- datos_train_multi_gradientes[, c("R_mediana", "G_mediana", "B_mediana", "H_mediana", "S_mediana", "V_mediana", "Sobel_mean", "Fuentes_luz", "Entropia", "Pixeles_oscuros", "Tonos_calidos", "Gradiente_H", "Gradiente_V")]
test_x_multi_gradientes <- datos_test_multi_gradientes[, c("R_mediana", "G_mediana", "B_mediana", "H_mediana", "S_mediana", "V_mediana", "Sobel_mean", "Fuentes_luz", "Entropia", "Pixeles_oscuros", "Tonos_calidos", "Gradiente_H", "Gradiente_V")]
train_y_multi_gradientes <- datos_train_multi_gradientes$etiqueta
test_y_multi_gradientes <- datos_test_multi_gradientes$etiqueta

set.seed(42)
rf_model_multi_gradientes <- randomForest(x = train_x_multi_gradientes, y = train_y_multi_gradientes, ntree = 100)
# Predecir en el conjunto de prueba
predicciones_rf_multi_gradientes <- predict(rf_model_multi_gradientes, newdata = test_x_multi_gradientes)
# Matriz de confusión
cm_rf_multi_gradientes <- confusionMatrix(predicciones_rf_multi_gradientes, test_y_multi_gradientes)
print(cm_rf_multi_gradientes)
cat("Precisión del modelo Random Forest con todas las características + Gradientes H y V para 3 clases (Día, Noche, Amanecer):", cm_rf_multi_gradientes$overall['Accuracy'] * 100, "%\n")

#sacar importancia del Random forest para cada caracteristica
importancia_multi_gradientes <- importance(rf_model_multi_gradientes)
print(importancia_multi_gradientes)
```

```{r}
# gradientes por bandas horizontales
extraer_gradientes_horizontales <- function(df_datos) {
  features <- numeric(nrow(df_datos))
  for (j in 1:nrow(df_datos)) {
    tryCatch({
      img <- readJPEG(df_datos$ruta[j])
      if (length(dim(img)) == 3) {
        r <- img[,,1]
        g <- img[,,2]
        b <- img[,,3]
        hsv_vals <- rgb_a_hsv(as.vector(r), as.vector(g), as.vector(b))
        V_channel <- matrix(hsv_vals[, 3], nrow = nrow(r),  ncol = ncol(r))
      } else {
        V_channel <- matrix(0, nrow = nrow(img), ncol = ncol(img))
      }
      # Dividir en 3 bandas horizontales
      altura <- nrow(V_channel)
      banda1 <- V_channel[1:floor(altura/3), ]
      banda2 <- V_channel[(floor(altura/3)+1):floor(2*altura/3), ]
      banda3 <- V_channel[(floor(2*altura/3)+1):altura, ]
      # Calcular gradientes verticales para cada banda
      gradiente_banda1 <- abs(diff(banda1, differences = 1, axis = 1))
      gradiente_banda2 <- abs(diff(banda2, differences = 1, axis = 1))
      gradiente_banda3 <- abs(diff(banda3, differences = 1, axis = 1))
      # Promediar los gradientes
      mean_gradiente <- mean(c(mean(gradiente_banda1, na.rm = TRUE),
                               mean(gradiente_banda2, na.rm = TRUE),
                               mean(gradiente_banda3, na.rm = TRUE)))
      features[j] <- mean_gradiente
    }, error = function(e) {
      cat("Error leyendo:", df_datos$ruta[j], "\n")
    })
  }
  df_final <- cbind(df_datos, Gradiente_V_bandas = features)
  df_final$etiqueta <- as.factor(df_final$etiqueta)
  return(df_final)
}
```
```{r}
# Aplicar la función a los conjuntos de datos
datos_train_multi_bandas <- extraer_gradientes_horizontales(datos_train_multi_gradientes)
datos_test_multi_bandas <- extraer_gradientes_horizontales(datos_test_multi_gradientes)
```

```{r}
#entrenar modelo con todas las caracteristicas hasta gradientes H y V + Gradientes bandas horizontales
train_x_multi_bandas <- datos_train_multi_bandas[, c("R_mediana", "G_mediana", "B_mediana", "H_mediana", "S_mediana", "V_mediana", "Sobel_mean", "Fuentes_luz", "Entropia", "Pixeles_oscuros", "Tonos_calidos", "Gradiente_H", "Gradiente_V", "Gradiente_V_bandas")]
test_x_multi_bandas <- datos_test_multi_bandas[, c("R_mediana", "G_mediana", "B_mediana", "H_mediana", "S_mediana", "V_mediana", "Sobel_mean", "Fuentes_luz", "Entropia", "Pixeles_oscuros", "Tonos_calidos", "Gradiente_H", "Gradiente_V", "Gradiente_V_bandas")]
train_y_multi_bandas <- datos_train_multi_bandas$etiqueta
test_y_multi_bandas <- datos_test_multi_bandas$etiqueta


set.seed(42)
rf_model_multi_bandas <- randomForest(x = train_x_multi_bandas, y = train_y_multi_bandas, ntree = 100)
# Predecir en el conjunto de prueba
predicciones_rf_multi_bandas <- predict(rf_model_multi_bandas, newdata = test_x_multi_bandas)
# Matriz de confusión
cm_rf_multi_bandas <- confusionMatrix(predicciones_rf_multi_bandas, test_y_multi_bandas)
print(cm_rf_multi_bandas)
cat("Precisión del modelo Random Forest con todas las características + Gradientes bandas horizontales para 3 clases (Día, Noche, Amanecer):", cm_rf_multi_bandas$overall['Accuracy'] * 100, "%\n")

#sacar importancia del Random forest para cada caracteristica
importancia_multi_bandas <- importance(rf_model_multi_bandas)
print(importancia_multi_bandas)
```
```{r}
# sacar el nombre de las imagenes que falla
indices_fallos <- which(predicciones_rf_multi_bandas != test_y_multi_bandas)
imagenes_fallidas <- datos_test_multi_bandas$ruta[indices_fallos]
print("Imágenes mal clasificadas:")
print(imagenes_fallidas)
```
```{r}
# division de la imagen en bloques. para cada bloque calcular mediana de V, desviacion de V, mediana de Hm porcentaje de pixeles brillantes
extraer_caracteristicas_bloques <- function(df_datos, num_bloques = 4) {
  features_list <- list()
  for (j in 1:nrow(df_datos)) {
    tryCatch({
      img <- readJPEG(df_datos$ruta[j])
      if (length(dim(img)) == 3) {
        r <- img[,,1]
        g <- img[,,2]
        b <- img[,,3]
        hsv_vals <- rgb_a_hsv(as.vector(r), as.vector(g), as.vector(b))
        H_channel <- matrix(hsv_vals[, 1], nrow = nrow(r), ncol = ncol(r))
        V_channel <- matrix(hsv_vals[, 3], nrow = nrow(r), ncol = ncol(r))
      } else {
        H_channel <- matrix(0, nrow = nrow(img), ncol = ncol(img))
        V_channel <- matrix(0, nrow = nrow(img), ncol = ncol(img))
      }
      altura <- nrow(V_channel)
      ancho <- ncol(V_channel)
      bloque_altura <- floor(altura / num_bloques)
      bloque_ancho <- floor(ancho / num_bloques)
      caracteristicas_bloques <- c()
      for (i in 0:(num_bloques - 1)) {
        for (k in 0:(num_bloques - 1)) {
          fila_inicio <- i * bloque_altura + 1
          fila_fin <- ifelse(i == num_bloques - 1, altura, (i + 1) * bloque_altura)
          col_inicio <- k * bloque_ancho + 1
          col_fin <- ifelse(k == num_bloques - 1, ancho, (k + 1) * bloque_ancho)
          bloque_H <- H_channel[fila_inicio:fila_fin, col_inicio:col_fin]
          bloque_V <- V_channel[fila_inicio:fila_fin, col_inicio:col_fin]
          mediana_H <- median(bloque_H, na.rm = TRUE)
          sd_V <- sd(as.vector(bloque_V), na.rm = TRUE)
          porcentaje_brillantes <- sum(bloque_V > 0.9) / length(bloque_V) * 100
          caracteristicas_bloques <- c(caracteristicas_bloques, mediana_H, sd_V, porcentaje_brillantes)
        }
      }
      features_list[[j]] <- caracteristicas_bloques
    }, error = function(e) {
      cat("Error leyendo:", df_datos$ruta[j], "\n")
    })
  }
  features_matrix <- do.call(rbind, features_list)
  colnames(features_matrix) <- paste0("Bloque_", rep(1:(num_bloques^2), each = 3),
                                      c("_Mediana_H", "_SD_V", "_Porcentaje_Brillantes"))
  df_final <- cbind(df_datos, features_matrix)
  df_final$etiqueta <- as.factor(df_final$etiqueta)
  return(df_final)
}
```
```{r}
# Aplicar la función a los conjuntos de datos
datos_train_multi_bloques <- extraer_caracteristicas_bloques(datos_train_multi_bandas, num_bloques = 4)
datos_test_multi_bloques <- extraer_caracteristicas_bloques(datos_test_multi_bandas, num_bloques = 4)
```

```{r}
#entrenar modelo con todas las caracteristicas hasta gradientes bandas horizontales + caracteristicas de bloques
train_x_multi_bloques <- datos_train_multi_bloques[, c("R_mediana", "G_mediana", "B_mediana", "H_mediana", "S_mediana", "V_mediana", "Sobel_mean", "Fuentes_luz", "Entropia", "Pixeles_oscuros", "Tonos_calidos", "Gradiente_H", "Gradiente_V", "Gradiente_V_bandas",
                                                       grep("Bloque_", colnames(datos_train_multi_bloques), value = TRUE))]
test_x_multi_bloques <- datos_test_multi_bloques[, c("R_mediana", "G_mediana", "B_mediana", "H_mediana", "S_mediana", "V_mediana", "Sobel_mean", "Fuentes_luz", "Entropia", "Pixeles_oscuros", "Tonos_calidos", "Gradiente_H", "Gradiente_V", "Gradiente_V_bandas",
                                                     grep("Bloque_", colnames(datos_test_multi_bloques), value = TRUE))]
train_y_multi_bloques <- datos_train_multi_bloques$etiqueta
test_y_multi_bloques <- datos_test_multi_bloques$etiqueta

set.seed(42)
rf_model_multi_bloques <- randomForest(x = train_x_multi_bloques, y = train_y_multi_bloques, ntree = 100)
# Predecir en el conjunto de prueba
predicciones_rf_multi_bloques <- predict(rf_model_multi_bloques, newdata = test_x_multi_bloques)
# Matriz de confusión
cm_rf_multi_bloques <- confusionMatrix(predicciones_rf_multi_bloques, test_y_multi_bloques)
print(cm_rf_multi_bloques)
cat("Precisión del modelo Random Forest con todas las características + Características de bloques para 3 clases (Día, Noche, Amanecer):", cm_rf_multi_bloques$overall['Accuracy'] * 100, "%\n")
#sacar importancia del Random forest para cada caracteristica
importancia_multi_bloques <- importance(rf_model_multi_bloques)
print(importancia_multi_bloques)
```
```{r}
# proporcion de pixeles extremos por bloque (extraer proporción de píxeles muy oscuros y muy brillantes en cada bloque)
extraer_pixeles_extremos_bloques <- function(df_datos, num_bloques = 4) {
  features_list <- list()
  for (j in 1:nrow(df_datos)) {
    tryCatch({
      img <- readJPEG(df_datos$ruta[j])
      if (length(dim(img)) == 3) {
        r <- img[,,1]
        g <- img[,,2]
        b <- img[,,3]
        hsv_vals <- rgb_a_hsv(as.vector(r), as.vector(g), as.vector(b))
        V_channel <- matrix(hsv_vals[, 3], nrow = nrow(r), ncol = ncol(r))
      } else {
        V_channel <- matrix(0, nrow = nrow(img), ncol = ncol(img))
      }
      altura <- nrow(V_channel)
      ancho <- ncol(V_channel)
      bloque_altura <- floor(altura / num_bloques)
      bloque_ancho <- floor(ancho / num_bloques)
      caracteristicas_bloques <- c()
      for (i in 0:(num_bloques - 1)) {
        for (k in 0:(num_bloques - 1)) {
          fila_inicio <- i * bloque_altura + 1
          fila_fin <- ifelse(i == num_bloques - 1, altura, (i + 1) * bloque_altura)
          col_inicio <- k * bloque_ancho + 1
          col_fin <- ifelse(k == num_bloques - 1, ancho, (k + 1) * bloque_ancho)
          bloque_V <- V_channel[fila_inicio:fila_fin, col_inicio:col_fin]
          total_pixeles_bloque <- length(bloque_V)
          pixeles_oscuros <- sum(bloque_V < 0.1)
          pixeles_brillantes <- sum(bloque_V > 0.9)
          proporcion_oscuros <- (pixeles_oscuros / total_pixeles_bloque) * 100
          proporcion_brillantes <- (pixeles_brillantes / total_pixeles_bloque) * 100
          caracteristicas_bloques <- c(caracteristicas_bloques, proporcion_oscuros, proporcion_brillantes)
        }
      }
      features_list[[j]] <- caracteristicas_bloques
    }, error = function(e) {
      cat("Error leyendo:", df_datos$ruta[j], "\n")
    })
  }
  features_matrix <- do.call(rbind, features_list)
  colnames(features_matrix) <- paste0("Bloque_", rep(1:(num_bloques^2), each = 2),
                                      c("_Proporcion_Oscuros", "_Proporcion_Brillantes"))
  df_final <- cbind(df_datos, features_matrix)
  df_final$etiqueta <- as.factor(df_final$etiqueta)
  return(df_final)
}
```

```{r}
# Aplicar la función a los conjuntos de datos
datos_train_multi_extremos <- extraer_pixeles_extremos_bloques(datos_train_multi_bloques, num_bloques = 4)
datos_test_multi_extremos <- extraer_pixeles_extremos_bloques(datos_test_multi_bloques, num_bloques = 4)
```

```{r}
#entrenar modelo con todas las caracteristicas hasta caracteristicas de bloques + proporcion de pixeles extremos por bloque
train_x_multi_extremos <- datos_train_multi_extremos[, c("R_mediana", "G_mediana", "B_mediana", "H_mediana", "S_mediana", "V_mediana", "Sobel_mean", "Fuentes_luz", "Entropia", "Pixeles_oscuros", "Tonos_calidos", "Gradiente_H", "Gradiente_V", "Gradiente_V_bandas",
                                                         grep("Bloque_", colnames(datos_train_multi_extremos), value = TRUE))]
test_x_multi_extremos <- datos_test_multi_extremos[, c("R_mediana", "G_mediana", "B_mediana", "H_mediana", "S_mediana", "V_mediana", "Sobel_mean", "Fuentes_luz", "Entropia", "Pixeles_oscuros", "Tonos_calidos", "Gradiente_H", "Gradiente_V", "Gradiente_V_bandas",
                                                       grep("Bloque_", colnames(datos_test_multi_extremos), value = TRUE))]
train_y_multi_extremos <- datos_train_multi_extremos$etiqueta
test_y_multi_extremos <- datos_test_multi_extremos$etiqueta

set.seed(42)
rf_model_multi_extremos <- randomForest(x = train_x_multi_extremos, y = train_y_multi_extremos, ntree = 100)
# Predecir en el conjunto de prueba
predicciones_rf_multi_extremos <- predict(rf_model_multi_extremos, newdata = test_x_multi_extremos)
# Matriz de confusión
cm_rf_multi_extremos <- confusionMatrix(predicciones_rf_multi_extremos, test_y_multi_extremos)
print(cm_rf_multi_extremos)
cat("Precisión del modelo Random Forest con todas las características + Proporción de píxeles extremos por bloque para 3 clases (Día, Noche, Amanecer):", cm_rf_multi_extremos$overall['Accuracy'] * 100, "%\n")

#sacar importancia del Random forest para cada caracteristica
importancia_multi_extremos <- importance(rf_model_multi_extremos)
print(importancia_multi_extremos)
```
